import feedparser
import datetime
import os
from pathlib import Path

# å–å¾—ã™ã‚‹RSSãƒ•ã‚£ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆï¼ˆãƒ•ã‚¡ãƒ“ã‚³ãƒ³ä»˜ãï¼‰
FEEDS = {
    "Tech Blog Weekly": {
        "url": "https://yamadashy.github.io/tech-blog-rss-feed/feeds/rss.xml",
        "favicon": "ğŸ’»"
    },
    "Qiita": {
        "url": "https://qiita.com/popular-items/feed", 
        "favicon": "https://cdn.qiita.com/assets/favicons/public/production-c620d3e403342b1022967ba5e3db1aaa.ico"
    },
    "Zenn": {
        "url": "https://zenn.dev/feed",
        "favicon": "https://zenn.dev/favicon.ico"
    },
    "ã¯ã¦ãªãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ - IT": {
        "url": "http://b.hatena.ne.jp/hotentry/it.rss",
        "favicon": "https://b.hatena.ne.jp/favicon.ico"
    }
}

# å„ãƒ•ã‚£ãƒ¼ãƒ‰ã‹ã‚‰å–å¾—ã™ã‚‹è¨˜äº‹ã®ä»¶æ•°
MAX_ENTRIES = 10

def fetch_feed_entries(feed_url):
    """æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰RSSãƒ•ã‚£ãƒ¼ãƒ‰ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’å–å¾—ã™ã‚‹"""
    try:
        feed = feedparser.parse(feed_url)
        return feed.entries
    except Exception as e:
        print(f"Error fetching feed from {feed_url}: {e}")
        return []

def generate_markdown(all_entries, feed_info, date_str):
    """å–å¾—ã—ãŸã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‹ã‚‰Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆã™ã‚‹"""
    markdown = f"# æ¯æ—¥ã®ãƒ†ãƒƒã‚¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ ({date_str})\n\n"
    markdown += "æ—¥æœ¬ã®ä¸»è¦ãªæŠ€è¡“ç³»ãƒ¡ãƒ‡ã‚£ã‚¢ã®æœ€æ–°äººæ°—ã‚¨ãƒ³ãƒˆãƒªãƒ¼ã‚’ãŠå±Šã‘ã—ã¾ã™ã€‚\n\n---\n"

    for feed_name, entries in all_entries.items():
        favicon = feed_info[feed_name]["favicon"]
        if favicon.startswith("http"):
            # ãƒ•ã‚¡ãƒ“ã‚³ãƒ³URLã®å ´åˆ
            favicon_display = f'<img src="{favicon}" width="16" height="16" alt="{feed_name}">'
        else:
            # çµµæ–‡å­—ã®å ´åˆ
            favicon_display = favicon
        markdown += f"## {favicon_display} {feed_name}\n\n"
        if not entries:
            markdown += "è¨˜äº‹ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚\n"
        else:
            for entry in entries[:MAX_ENTRIES]:
                title = entry.title
                link = entry.link
                markdown += f"- [{title}]({link})\n"
        
        markdown += "\n---\n"
    
    return markdown

def save_to_archive(content, date_obj):
    """æ—¥ä»˜åˆ¥ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜"""
    year = date_obj.year
    month = f"{date_obj.month:02d}"
    date_str = date_obj.isoformat()
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    archive_dir = Path(f"archives/{year}/{month}")
    archive_dir.mkdir(parents=True, exist_ok=True)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼ˆæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯ä¸Šæ›¸ãï¼‰
    archive_file = archive_dir / f"{date_str}.md"
    if archive_file.exists():
        print(f"Overwriting existing archive: {archive_file}")
    else:
        print(f"Creating new archive: {archive_file}")
    
    with open(archive_file, "w", encoding="utf-8") as f:
        f.write(content)
    
    return archive_file

def update_monthly_index(year, month):
    """æœˆåˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°"""
    archive_dir = Path(f"archives/{year}/{month:02d}")
    if not archive_dir.exists():
        return
    
    # ãã®æœˆã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
    md_files = sorted([f for f in archive_dir.iterdir() if f.suffix == '.md' and f.name != 'index.md'])
    
    # æœˆåˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    index_content = f"# {year}å¹´{month}æœˆã®ãƒ†ãƒƒã‚¯ãƒ‹ãƒ¥ãƒ¼ã‚¹\n\n"
    index_content += f"{year}å¹´{month}æœˆã«å–å¾—ã—ãŸãƒ†ãƒƒã‚¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®ä¸€è¦§ã§ã™ã€‚\n\n"
    
    for md_file in reversed(md_files):  # æ–°ã—ã„é †
        date_str = md_file.stem
        index_content += f"- [{date_str}]({md_file.name})\n"
    
    index_content += f"\n[â† {year}å¹´ä¸€è¦§ã«æˆ»ã‚‹](../index.md)\n"
    
    with open(archive_dir / "index.md", "w", encoding="utf-8") as f:
        f.write(index_content)

def update_yearly_index(year):
    """å¹´åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°"""
    year_dir = Path(f"archives/{year}")
    if not year_dir.exists():
        return
    
    # ãã®å¹´ã®æœˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§ã‚’å–å¾—
    month_dirs = sorted([d for d in year_dir.iterdir() if d.is_dir() and d.name.isdigit()])
    
    # å¹´åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    index_content = f"# {year}å¹´ã®ãƒ†ãƒƒã‚¯ãƒ‹ãƒ¥ãƒ¼ã‚¹\n\n"
    index_content += f"{year}å¹´ã«å–å¾—ã—ãŸãƒ†ãƒƒã‚¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®æœˆåˆ¥ä¸€è¦§ã§ã™ã€‚\n\n"
    
    for month_dir in reversed(month_dirs):  # æ–°ã—ã„é †
        month = int(month_dir.name)
        index_content += f"- [{year}å¹´{month}æœˆ]({month_dir.name}/index.md)\n"
    
    index_content += f"\n[â† ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ä¸€è¦§ã«æˆ»ã‚‹](../index.md)\n"
    
    with open(year_dir / "index.md", "w", encoding="utf-8") as f:
        f.write(index_content)

def update_archive_index():
    """ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–å…¨ä½“ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°"""
    archives_dir = Path("archives")
    if not archives_dir.exists():
        return
    
    # å¹´ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä¸€è¦§ã‚’å–å¾—
    year_dirs = sorted([d for d in archives_dir.iterdir() if d.is_dir() and d.name.isdigit()])
    
    # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
    index_content = "# ãƒ†ãƒƒã‚¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–\n\n"
    index_content += "éå»ã®ãƒ†ãƒƒã‚¯ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å¹´åˆ¥ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã§ã™ã€‚\n\n"
    
    for year_dir in reversed(year_dirs):  # æ–°ã—ã„é †
        year = year_dir.name
        index_content += f"- [{year}å¹´]({year}/index.md)\n"
    
    index_content += f"\n[â† ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã«æˆ»ã‚‹](../README.md)\n"
    
    with open(archives_dir / "index.md", "w", encoding="utf-8") as f:
        f.write(index_content)

def update_readme_with_archive_link(content):
    """README.mdã«ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã¸ã®ãƒªãƒ³ã‚¯ã‚’è¿½åŠ """
    lines = content.split('\n')
    
    # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒªãƒ³ã‚¯ã‚’æŒ¿å…¥ã™ã‚‹ä½ç½®ã‚’æ¢ã™
    insert_index = 2  # ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜ã®å¾Œ
    
    # æ—¢å­˜ã®ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒªãƒ³ã‚¯ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    archive_link_exists = any("ğŸ“š [éå»ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¦‹ã‚‹]" in line for line in lines)
    
    if not archive_link_exists:
        archive_link = "\nğŸ“š [éå»ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¦‹ã‚‹](archives/index.md)\n"
        lines.insert(insert_index, archive_link)
    
    return '\n'.join(lines)

if __name__ == "__main__":
    today = datetime.date.today()
    
    all_entries = {}
    for name, feed_info in FEEDS.items():
        print(f"Fetching entries from {name}...")
        entries = fetch_feed_entries(feed_info["url"])
        all_entries[name] = entries
    
    # Markdownã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
    markdown_content = generate_markdown(all_entries, FEEDS, today.isoformat())
    
    # ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã«ä¿å­˜
    archive_file = save_to_archive(markdown_content, today)
    print(f"Archived to: {archive_file}")
    
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒšãƒ¼ã‚¸æ›´æ–°
    update_monthly_index(today.year, today.month)
    update_yearly_index(today.year)
    update_archive_index()
    
    # README.mdæ›´æ–°ï¼ˆã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒªãƒ³ã‚¯ä»˜ãï¼‰
    readme_content = update_readme_with_archive_link(markdown_content)
    with open("README.md", "w", encoding="utf-8") as f:
        f.write(readme_content)
        
    print(f"Successfully updated README.md and archive structure.")